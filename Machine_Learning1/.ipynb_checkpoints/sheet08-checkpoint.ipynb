{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees, Random Forests, Boosting (40 P)\n",
    "\n",
    "The goal of this homework is to extend decision trees, using (1) random forests or (2) boosting. For this, we will make use of an existing decision tree implementation (available in `scikit-learn`), that we can then reuse for implementing the two models of interest. As a first step, we download a simple two-dimensional classification dataset: the Iris data. The following code loads the data and retains only the first two input dimensions so that the problem can be easily visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy,utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn,sklearn.datasets\n",
    "iris = sklearn.datasets.load_iris()\n",
    "X,T = iris.data[:,:2],iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `plot_iris` from the modules `utils.py` takes as input a classification function mapping a data matrix containing the two input features for each data point a vector representing the classification of each data point. Then, the `plot_iris` function plots the decision function in superposition to the Iris dataset. In the example below, the prediction function assigns to each data point the output 0 (corresponding to the first class, shown in red)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = lambda X: numpy.dot(X,[0,0])\n",
    "G = numpy.meshgrid(numpy.arange(4,8.1,0.1),numpy.arange(2,4.6,0.1))\n",
    "D = numpy.array([G[0].flatten(),G[1].flatten()]).T\n",
    "Y = predict(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[4. , 4.1, 4.2, ..., 7.8, 7.9, 8. ],\n",
       "        [4. , 4.1, 4.2, ..., 7.8, 7.9, 8. ],\n",
       "        [4. , 4.1, 4.2, ..., 7.8, 7.9, 8. ],\n",
       "        ...,\n",
       "        [4. , 4.1, 4.2, ..., 7.8, 7.9, 8. ],\n",
       "        [4. , 4.1, 4.2, ..., 7.8, 7.9, 8. ],\n",
       "        [4. , 4.1, 4.2, ..., 7.8, 7.9, 8. ]]),\n",
       " array([[2. , 2. , 2. , ..., 2. , 2. , 2. ],\n",
       "        [2.1, 2.1, 2.1, ..., 2.1, 2.1, 2.1],\n",
       "        [2.2, 2.2, 2.2, ..., 2.2, 2.2, 2.2],\n",
       "        ...,\n",
       "        [4.3, 4.3, 4.3, ..., 4.3, 4.3, 4.3],\n",
       "        [4.4, 4.4, 4.4, ..., 4.4, 4.4, 4.4],\n",
       "        [4.5, 4.5, 4.5, ..., 4.5, 4.5, 4.5]])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26, 41), (26, 41))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G[0].shape, G[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1066,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G[0].flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1066, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1066,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQcAAACrCAYAAABrAlmGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUtklEQVR4nO2df5BV5XnHP8/ehWsWA2YiVas0OPH3NHazIhJMGYu10yBDarRVx/ygptFmtNFQq9U/lDBTUqMyacuYSghRDDVaNNUgWh1XB80GCaxb/Bk1lfgj/kCNIhAv7u7TP+7dcnd9z+5997znxz33+czscO/Z977nOTD34bzf93ueR1QVwzCMkbRlHYBhGPnEkoNhGE4sORiG4cSSg2EYTiw5GIbhxJKDYRhOGk4OIlISkcdEZJ3jdwtFZLuI9NV+/iZsmIZhpE27x9iLgKeByRG/v1VVL4wfkmEYeaChOwcROQQ4FViZbDiGYeSFRpcV3wUuBQZHGXO6iGwVkbUiMi12ZIZhZMqYywoRmQ+8oapbROSkiGE/BW5R1YqInA/cBMx1zHUecB7ApH32Oe6IaQePN27DMMbJY8/96k1VnTrWOBnr2QoR+TbwJaAf2Ieq5nCHqn4xYnwJeFtVp4w2b9cRh+nPrr92rPgMwwhMxymnbVHVGWONG3NZoaqXq+ohqjodOAvoHpkYROSgurcLqAqXhmE0MT67FcMQkSXAZlW9C/iGiCygenfxNrAwTHhGaNp6NlHq7WOgq5PB2TOzDsfIMV7JQVUfAh6qvb6y7vjlwOUhAzPC09aziYlLlyGVCqV7u9lzxSJLEEYk5pBsIUq9fUilAlBNEL192QZk5BpLDi3EQFcnWi4DoOUyA12d2QZk5Jpxaw5G8zE4eyZ7rlhkmoPREJYcWozB2TMtKRgNYcsKwzCcWHIwDMOJJQfDMJxYcjAMw4klB8MwnNhuRQEwS7SRBHbn0OQMWaLb77yHiUuX0dazKeuQjIJgyaHJMUu0kRSWHJocs0QbSWGaQ5NjlmgjKSw5FACzRBtJYMkhY2ynwcgrpjlkiO00GHnGkkOG2E6DkWdCtcMri8itIvK8iDwqItODRllQbKfByDOh2uF9Ffitqh4mImcBVwNnBoiv0NhOg5FnGkoOde3w/glY5BjyeWBx7fVaYLmIiI7VFMPIzU6DCaPGSEK1wzsYeAlAVfuBd4GPxw3OSAcTRg0XYyaH+nZ4cU8mIueJyGYR2fzmuzviTmcEwoRRw0Ujdw4nAgtEZBvwY2CuiPxoxJhXgGkAItIOTAHeGjmRqq5Q1RmqOmP/KS7pwsgCE0YNF2NqDvUNa2qNdC9x9Mm8C/gK8HPgDKot80xvaBJMGDVchGqH9wPgZhF5nmo7vLMCxWekRF6EUSM/hGqH9z7wlyEDMz5M+6o1lDZuYmDWTPrPPSfrcIyCY89WNAntq9bQfstaBJAXXgSwBGEkitmnm4TSxk1I7bXU3htGklhyaBIGZs1kSOHV2nvDSBJbVjQJQ0sI0xyMtLDkkCITllxDqW8rA53H8sGV/+D9+f5zz4mdFMwm3dys6zmQB3qncnLXdubPfi3YWBe2rEiJCUuuofRwD/LeTkoP9zBhyTWpx2A26eZmXc+BLFw6gxvu/CQLl85gXc+BQcZGYckhJUp9W4cLin1b04/BbNJNzQO9U9ldqd7s766080Dv1CBjo7DkkBIDnccOFxQ7j00/BrNJNzUnd22no9wPQEe5n5O7tgcZG4Vk5XLuOuIw/dn112Zy7qyIqzmEwDSH5iaE5tBxymlbVHXGWOey5JAiPl9M11j7YhshaDQ52G5FSgyJgVKpULq3mz1XLIr8grvGAg1/3jBCYJpDSviIga6xJiYaaWPJISV8xEDXWBMTjbSxZUVK+NRMiBprNReMNDFB0jBaDBMkGyCu+h/1edtVaB3iWpTzTMtqDnGtxFGfN4ty6xDCopxnWjY5xFX/oz5vuwqtQwiLcp5p2eQQV/2P+rztKrQOISzKeWZMQVJE9gE2AGWqGsVaVb1qxJiFwDVUS9QDLFfVlaPNmwdB0jQHIy7NqDmEFCQrwFxV3SkiE4BHROQeVd04YtytqnrheILNirgVl6M+3/bMc7RtfRLtmDTs964CsSESiSWj7Jg/+7WmSQq+NNK3QoGdtbcTaj/WkyKCqEKwruODRx0e2xLtY8s2DB8a0hxEpCQifcAbwP2q+qhj2OkislVE1orItIh5Ct8OL6oQrOt4CPHSBFAjKRpKDqo6oKqdwCHATBH5wxFDfgpMV9VjgfuBmyLmKXw7vKhCsK7jIcRLE0CNpPBtavOOiDwI/DnwRN3x+r6YK4HvhAmv+YgqBBt1PK4l2lrZGUnRyG7FVOCDWmL4CHAfcLWqrqsbc5Cqvlp7fRpwmarOGm3ePOxWGEYrEnK34iDgJhEpUV2G3Kaq60b0yvyGiCwA+qn2ylw4/tDTw0fl92lFFzU2bgGXvLTDa6tsolTpY6DcyWB59JijtvqacQuw1WjZB6/qVX4tl0dV+et3GhToP/uMyC9n1FjX+YBEYkiStsomJr67DKGCUmbPlEWRCWLIXry70k5HuZ8br9jM/NmvRR430qHRO4eWdUh6FV/xaEUXuVsRs4BLXtrhlSp9CLWYqVCq9EWOjbIXF912XBRaNjl4FV/xaEUXuVsRs4BLXtrhDZQ7UWoxU2ag3Bk5NspeXHTbcVFo2WUFmOYwXkxzaG6snkMD+NinfVrRDR51OLJ7F4NHHZ5ZDEkyWJ45ZlIYIspe3Nb/LKXKG7T1vwOE87wsXnU0d288gFNnvc7ic58ONm8r0tLJIQmi7Mxmc97L+g07+PLVp7N7zyRu7N7Fam5n3pz4CWLxqqP5zi1HAMKTL0ypHrMEMW5aVnNICqvzMDbdv9iP3XsmAbB7zyS6f7FfkHnv3ngA1Mm21ffGeLHkEBir8zA2c49/h46JuwDomLiLuce/E2TeU2e9DnWybfW9MV5sWRGYKDuz2Zz3Mm/OZFZzO92/2I+5x78TZEkBe5cQpjmEoaV3KwyjFWlZE1RbzyYmLF/RUGFX19j2VWson3cR7avWpBJDnmmrbGLCjhW0VdK5jvUbdnDJdW2s3zD8cf51PQfyzeWfGncB16jPRx33ue64seWZQt05+FiiXWPbnnkutkXZJ4Y842OTDkH9DkbHxF2svqy6gxHXau1r4Q5hD887LXnnELsfZQCLclF2JXxs0iGI2sGIa7X2tXCHsIcXhUIlh9j9KANYlIuyK+Fjkw5B1A5GXKu1r4U7hD28KBRqWQF+dmTX2BAW5aIUfPWxSYdg/YYdzh2MuFZrXwt3CHt4nml0WVG45OBDHhKJsZcQX7R7un9Jd+8BzO16nc/NPXLUsd/6/mTu3jidU2dt46qvFbOmqQt7tmIMfOzMrrH14mV9lWljfNSLezff+4lxiXv3dP+SL113Ibv3TOKHD+7iZpZHJohvfX8yV9/2J4DwxIuHAg+2VIJohEJpDj7kQbw09hJC3OvuPWC4qNkbbZ++e+N0hlutp3ufr+i0bHLIg3hp7CWEuDe36/XhomZXtH361FnbGG613uZ9vqITqh1eGVgNHAe8BZypqttGm9c0B2MkpjmkQ9rt8L4K/FZVDxORs4CrgTPHFXmDhOhT6VNLwdXiLqpuQ1K7FT4qevvONZQqmxgoz6R/37qCMx5z+OweRI31Iar2wzlLZvBQ3/6c1Pkma67cPOp1aPtBqOyHtu+9KY5KOld9bQdXfW1rQ7GlXbQmD0VyvHYrRKQDeAT4en3XKxH5b2Cxqv5cRNqB14CpOsrkce4colyISbkTXcVd61vZpRGDj3Ovfeca2nfXxdtxBv37nuM1h49jsa3/WefYEJyzZAY/efhgqF3NaX/8Crdcdr3zOlwxD7YfEdvFmHah3KTPF9Qh2UA7vIOBlwBUtR94F/i4Y54g7fDSrpng08ousRg8nHulyoh4a88I+Mzh41hMqj4DwEN9+1MvHD7Ut3/kdbjiCCF0pl0oNy+FeUO1w2uIUO3w0q6Z4NPKLrEYPJx7A+UR8dbuDnzm8HEsJlWfAeCkzjepFw5P6nwz8jpccYQQOtMulJuXwrzeJigRuRLYrarX1h1LdVkBYTQHH1ziY9oxFF1ziMJHc3DFEWKdXiTNIZhDssF2eBcAn1LVv60Jkl9Q1b8abd487FYYRiuSdju8HwA3i8jzVNvhnRUj9lgU5bmGuET9zxrieQnXHL7nc/0P6BNb2s99+NCMz1u4KNSzFUWppRCXqF2JEDUaXHMAXudzqe4Ljrur4djSrjXhQzPUeLB6Dk1cSyEuUWp+iBoNrjl8z+dS3f12Y9KtNeFDkWo8FCo5FKWWQlyi1PwQNRpcc/iez6W6++3GpFtrwoci1Xgo1LICTHMYwjSH7Mi75tCyj2z7WKKLzF1bFvBA71c/XMjkg+do++BJtG3SmF/WKFzt8KLmjYrDxZVrvsLdGy/9UFl5VyLwacmXdiKJsoEnuaWaBIW7czCiRbEoW3VcEc13Xtfxzc987P9b2YFy6dnPsvjcp2OLj3kRL0MIlbm0TxvNRXTxVLetOq6I5juv63hUK7u44mNexMskbdxJYcmhgEQXT3XbquOKaL7zuo5HtbKLKz7mRbxM0sadFLasKChRa9MoW3XctazvvK7ji1cd7WxlF1czyIt4mRfNwQrMGobhxDSHJiGplnO+8y65YYCZ5x7JkhsGgs/twtVGrsit5ZqRwm1lNhP1Snrp/e5gSrrvvEtuGOCf134BEJ546SjgDq48v5RYzK5K00Ds6tNGWOzOIUOSUtJ951336DHU7xRU34eZ24VLdS+S7bgoWHLIkKSUdN9555/wFPU7BdX3YeZ24VLdi2Q7LgomSGZMUkq677xLbhhg3aPHMP+EpyKXFOOd24VLdc+77bgo2G5FCxHimYS4X3j7YqdDmluZtqxocoYEwvb372Hiu8tG3UGIGuszh4shgfGGOz/JwqUzbLchIdL+e7bk0OSEqIMQV2Q0MTEdzD5teBGiDkJckdHExHTInX1aRKZRbXV3AFVJe4Wq/suIMScBdwIv1A7doapLRpvXNIdwmObQOuTKPi0iBwEHqWqviHwU2AL8hao+VTfmJOASVZ3faICWHAwjG4IJkqr6qqr21l6/BzxNtcNVy+Nr903TKh11rrxYlNdv2MEl17WxfkPYBrZ5ub4i4GWfFpHpwKeBke3wAD4jIv8D/IbqXcST8cPLLy4L8Gi3eWlapQHnuXxjTor6npY3du9iNWF6a+bl+opCw4KkiOwL3A5crKoj030v8AlV/SPg34D/ipgjSK/MPOCrHKdplfap+pwFSfXWzMv1FYVGG+lOoJoY1qjqHSN/r6o7VHVn7fV6YIKI7O8YF6RXZh7wVY7TtEr7VH3OgqR6a+bl+opCI4KkADcBb6vqxRFjDgReV1UVkZnAWqp3Eon1yswDvspxmlZpn6rPWZBUb828XF+eCblb8VngYeBxYLB2+ArgDwBU9d9F5ELg60A/8Dtgkar2jDZvEZJDXioMRVVhMgwXwUrTq+oj7H2eN2rMcmB54+E1P0kJjL7UV36W3S8CWIIwgmAOyXGSl6rGUZWfDSMulhzGSV6qGkdVfjaMuFiZuHEyWJ7JnimLMtcchpYQpjkYoWmJ5JBU/8yolmxpC5WDEw5HBncxOOHwxM8ViryIuUY0hV9WtPVsYuLSZbTfeQ8Tly6jrSfZNXnc2gh5P18ImjHmVqTwyaHU24dUasJhpUKpty/Z86UsVOZFGPWhGWNuRQqfHAa6OtFyTTgslxno6kz2fCkLlXkRRn1oxphbkcJrDoOzZ7LnikWJaA7O86UsVOZFGPWhGWNuRQqfHKCaIJJOCsPOFyFUFuV8IWjGmFuNwi8rjPD41GJIqoaFkTwtcedghMOnFkNeLObG+LA7B8MLn1oMtivR3FhyMLzwqcVguxLNjS0rDC/mzZnMam5vqBaD7Uo0N5YcDG/mzZnMvDmDwNhFWmxXonmxZYVhGE4sORiG4cSSg2EYTsZMDiIyTUQeFJGnRORJEbnIMUZE5F9F5HkR2SoiXcmEaxhGWjQiSPYDf1/fDk9E7q9vhwd8Dji89nMC8L3an4ZhNCmh2uF9HlitVTYC+9V6bLYkZhk2ioCX5jBKO7yDgZfq3r9Mi/bTtEImRlFo2OcwRju8Ruc4Dziv9rbSccppT4xnnjwzfSrTPr4vv7f9PZj60Qpv7fz2G9u2D0ucRWF/4M2sg0iQIl/fkY0Maig5jNUOD3gFmFb3/pDasWGo6gpgRW3OzY001mhWRGTzr7cX+/qK/u9X1OsTkc2NjGtkt0KAHwBPq+qyiGF3AV+u7VrMAt5V1VcbjtYwjNzRyJ3DicCXgMdFpK92bFg7PGA9MA94HtgN/HXwSA3DSJVQ7fAUuMDz3Cs8xzcbdn3NTZGvr6FrG7ORrmEYrYnZpw3DcJJZchCRkog8JiLrsoohKURkm4g8LiJ9jSrDzYKI7Ccia0XkGRF5WkQ+k3VMoRCRI2v/ZkM/O0Tk4qzjComIfLP2GMQTInKLiOwTOTarZYWILAJmAJNVdX4mQSSEiGwDZqhq4fbJReQm4GFVXSkiE4EOVX0n47CCIyIlqtvxJ6jqr7OOJwQicjDwCHCMqv5ORG4D1qvqja7xmdw5iMghwKnAyizOb4wPEZkCzKG6tY2q7iliYqhxMvCroiSGOtqBj4hIO9AB/CZqYFbLiu8ClwKDGZ0/aRS4T0S21FyhReFQYDvww9qScKWITMo6qIQ4C7gl6yBCoqqvANcCLwKvUvUj3Rc1PvXkICLzgTdUdUva506Rz6pqF9WnVS8QkTlZBxSIdqAL+J6qfhrYBfxjtiGFp7ZcWgD8Z9axhEREPkb1IclDgd8HJonIF6PGZ3HncCKwoLYu/zEwV0R+lEEciVHL0KjqG8BPgKIUUXwZeFlVhx68W0s1WRSNzwG9qvp61oEE5k+BF1R1u6p+ANwBzI4anHpyUNXLVfUQVZ1O9datW1Ujs1ezISKTanUvqN1y/xlQiAfMVPU14CURGXpw52TgqVE+0qycTcGWFDVeBGaJSEftsYiTqZZgcGLVp8NzAPCT6t897cB/qOq92YYUlL8D1tRuvf+Xglnlawn9FOD8rGMJjao+KiJrgV6qRZweYxS3pDkkDcNwYg5JwzCcWHIwDMOJJQfDMJxYcjAMw4klB8MwnFhyMAzDiSUHwzCcWHIwDMPJ/wF7Dqp31ZuKlgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy,utils\n",
    "utils.plot_iris(X,T,lambda X: numpy.dot(X,[0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "We now consider the decision tree classifier readily available in `scikit-learn`. We use the default parameters of the classifier and only specify its the maximum tree depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.tree\n",
    "classifier = sklearn.tree.DecisionTreeClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test the prediction accuracy of the classifier, one needs to split the dataset into a training and test set. The function `utils.split` achieves this by assigning a random 50% of the data for training and the remaining 50% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Xtrain,Ttrain),(Xtest,Ttest) = utils.split(X,T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the splitting is done, the training data can be used to fit the classifier. The learned prediction function and the test data are then sent to the Iris plotting function to visualize the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier.fit(Xtrain,Ttrain)\n",
    "utils.plot_iris(Xtest,Ttest,classifier.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = numpy.meshgrid(numpy.arange(4,8.1,0.1),numpy.arange(2,4.6,0.1))\n",
    "D = numpy.array([G[0].flatten(),G[1].flatten()]).T\n",
    "Y = classifier.predict(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the classifier does a reasonable job at classifying the data, although the decision boundaries are a bit too rectangular, and somewhat unnatural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier (10 P)\n",
    "\n",
    "We would like to now compare the decision boundary of the decision tree with the one obtained with a random forest classifier. We consider a random forest composed of 100 trees. Each tree is trained on 50% subset of the training set. (Hint: The function `utils.split` can be called with seeds from 0 to 100 in order to build these random subsets.) The prediction function should implement a majority voting between each tree in the forest. Voting ties do not need to be handled in a particular way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **Implement the `fit` and `predict` functions of the random forest classifier below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestClassifier:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.trees = [sklearn.tree.DecisionTreeClassifier(max_depth=5)\n",
    "                      for _ in range(100)]\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        \n",
    "        for i in range(len(self.trees)):\n",
    "            (Xtrain, Ttrain), (_, _) = utils.split(X, y, i)\n",
    "            self.trees[i].fit(Xtrain, Ttrain)\n",
    "            # self.trees[i].fit(Xtrain[: Xtrain.shape[0] // 2 ,:],Ttrain[: Ttrain.shape[0] // 2])\n",
    "\n",
    "    \n",
    "    def predict(self,X):\n",
    "        \n",
    "        G = numpy.meshgrid(numpy.arange(4,8.1,0.1),numpy.arange(2,4.6,0.1))\n",
    "        D = numpy.array([G[0].flatten(),G[1].flatten()]).T\n",
    "        \n",
    "        predictions = self.trees[0].predict(D)[numpy.newaxis, :]\n",
    "        for i in range(len(self.trees)-1):\n",
    "            predictions = numpy.concatenate( (predictions, self.trees[i+1].predict(D)[numpy.newaxis, :]) )\n",
    "        predictions = numpy.array( [ numpy.argmax( numpy.bincount( vote )) for vote in predictions.T ] )\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below runs the random forest classifier on the same dataset as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cl = RandomForestClassifier()\n",
    "\n",
    "(Xtrain,Ttrain),(Xtest,Ttest) = utils.split(X,T)\n",
    "cl.fit(Xtrain,Ttrain)\n",
    "utils.plot_iris(Xtest,Ttest,cl.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the decision boundary obtained by a single decision tree, the random forest tends to produce more curved and natural-looking decision functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative Experiments\n",
    "\n",
    "We now focus on understanding more quantitatively the effect on the model accuracy of choosing different models and their parameters. For this, we switch to the regression case, and consider two different datasets also available in `scikit-learn`, the boston dataset, and the diabetes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston   = sklearn.datasets.load_boston()\n",
    "diabetes = sklearn.datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `utils.py` provides a method `benchmark`, that tests the performance of a model on 100 different train/test splits, and returns the average training and test performance scores. For regression task, the performance score is given by the R2 coefficient of determination (see here https://en.wikipedia.org/wiki/Coefficient_of_determination). A score of \"1\" is optimal. A score of \"0\" is essentially random guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 0.938 | test score: 0.731\n"
     ]
    }
   ],
   "source": [
    "regressor = sklearn.tree.DecisionTreeRegressor(max_depth=5)\n",
    "strain,stest = utils.benchmark(regressor,boston)\n",
    "print('training: %.3f | test score: %.3f'%(strain,stest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, the test data is predicted fairly well with a coefficient determination above 0.7. Furthermore, we can investigate the effect of depth on the decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth: 1 | training score: 0.479 | test score: 0.382\n",
      "depth: 2 | training score: 0.717 | test score: 0.630\n",
      "depth: 3 | training score: 0.835 | test score: 0.683\n",
      "depth: 4 | training score: 0.904 | test score: 0.729\n",
      "depth: 5 | training score: 0.938 | test score: 0.724\n",
      "depth: 6 | training score: 0.962 | test score: 0.723\n",
      "depth: 7 | training score: 0.976 | test score: 0.717\n",
      "depth: 8 | training score: 0.986 | test score: 0.718\n",
      "depth: 9 | training score: 0.992 | test score: 0.714\n"
     ]
    }
   ],
   "source": [
    "for d in range(1,10):\n",
    "    regressor = sklearn.tree.DecisionTreeRegressor(max_depth=d)\n",
    "    strain,stest = utils.benchmark(regressor,boston)\n",
    "    print('depth: %d | training score: %.3f | test score: %.3f'%\n",
    "                                                 (d,strain,stest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the training error keeps increasing, the test error saturates once a depth of 5 has been reached. The same experiment can be performed on the diabetes dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth: 1 | training score: 0.319 | test score: 0.220\n",
      "depth: 2 | training score: 0.462 | test score: 0.334\n",
      "depth: 3 | training score: 0.557 | test score: 0.315\n",
      "depth: 4 | training score: 0.649 | test score: 0.256\n",
      "depth: 5 | training score: 0.739 | test score: 0.182\n",
      "depth: 6 | training score: 0.820 | test score: 0.110\n",
      "depth: 7 | training score: 0.884 | test score: 0.046\n",
      "depth: 8 | training score: 0.930 | test score: -0.010\n",
      "depth: 9 | training score: 0.960 | test score: -0.036\n"
     ]
    }
   ],
   "source": [
    "for d in range(1,10):\n",
    "    regressor = sklearn.tree.DecisionTreeRegressor(max_depth=d)\n",
    "    strain,stest = utils.benchmark(regressor,diabetes)\n",
    "    print('depth: %d | training score: %.3f | test score: %.3f'%\n",
    "                                                  (d,strain,stest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the best depth is just 2, and the model quality seriously degrades as we continue growing the tree. This is the result of overfitting, i.e. as we make the model closer to the data (bias reduction), we are also become highly sensitive to noise in the data and in the sampling process (variance increase)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a Random Forest Regressor (10 P)\n",
    "\n",
    "One way of reducing variance is to average a large number of models. This is the idea of random forests. Here, we consider a random forest regressor. Like for the random forest classifier, each tree is grown on a random subset of the training set containing only half of the examples. As in the first exercise, the function `utils.split` can be used to generate these subsets. Because we are now implementing a regression model, we replace the majority voting by a simple averaging of the prediction of the different trees. The implementation below inherits some useful methods from the class `sklearn.base.RegressorMixin` in particular the function `score` measuring the coefficient of determination, which therefore does not need to be reimplemented.\n",
    "\n",
    " * **Implement the `fit` and `predict` functions of the random forest regressor below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestRegressor(sklearn.base.RegressorMixin):\n",
    "    \n",
    "    def __init__(self,max_depth=None,nb_trees=10):\n",
    "        self.trees = [sklearn.tree.DecisionTreeRegressor(max_depth=max_depth)\n",
    "                      for _ in range(nb_trees)]\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        \n",
    "        for i in range(len(self.trees)):\n",
    "            (Xtrain, Ttrain), (_, _) = utils.split(X, y, i)\n",
    "            self.trees[i].fit(Xtrain, Ttrain)\n",
    "\n",
    "    def predict(self,X):\n",
    "        predictions = numpy.array( [ tree.predict(X) for tree in self.trees ] )\n",
    "        return numpy.mean([ tree.predict(X) for tree in self.trees ], axis=0)\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check whether the random forest brings an improvement over the simple decision tree algorithm, we select the best decision tree obtained so far (`d=7`), and compare its accuracy to our random forest regressor. Here, because of the averaging effect of the random forest, we can afford higher depths, for example, `d=9`. The code below test the performance of random forests of increasingly many trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree (optimal depth): | train: 0.976 | test: 0.718\n",
      "random forest with  1 tree(s): | train: 0.813 | test: 0.645\n",
      "random forest with  2 tree(s): | train: 0.883 | test: 0.734\n",
      "random forest with  4 tree(s): | train: 0.921 | test: 0.790\n",
      "random forest with  8 tree(s): | train: 0.938 | test: 0.813\n",
      "random forest with 16 tree(s): | train: 0.947 | test: 0.826\n",
      "random forest with 32 tree(s): | train: 0.951 | test: 0.831\n"
     ]
    }
   ],
   "source": [
    "# Benchmark for baseline decision tree model\n",
    "regressor = sklearn.tree.DecisionTreeRegressor(max_depth=7)\n",
    "strain,stest = utils.benchmark(regressor,boston)\n",
    "print(\"decision tree (optimal depth): | train: %.3f | test: %.3f\"%\n",
    "      (strain,stest))\n",
    "\n",
    "# Benchmark for the random forest model with a growing number of trees\n",
    "for nb_trees in [1,2,4,8,16,32]:\n",
    "    regressor = RandomForestRegressor(max_depth=9,nb_trees=nb_trees)\n",
    "    strain,stest = utils.benchmark(regressor,boston)\n",
    "    print(\"random forest with %2d tree(s): | train: %.3f | test: %.3f\"%\n",
    "          (nb_trees,strain,stest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be observed from the results above, the test scores of a random forest are much better. Due to their high performance, random forests are often used in practical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a Simple Boosted Tree Regressor (20 P)\n",
    "\n",
    "Another extension to the simple decision tree regressor, is the boosted tree regressor. Here, instead of averaging a large number of trees grown from randomly sampled data, the extra trees serve to predict what the previous trees failed to predict, i.e. the residual error. Technically, the variant of the boosted tree regressor we consider here is defined as follows:\n",
    "\n",
    "Let $F_k(x) = f_1(x) + f_2(x) + \\dots + f_k(x)$ be the prediction of a boosted regressor with $k$ trees, and some ground truth function $y(x)$, the next boosted regressor adds an additional decision tree $f_{k+1}(x)$ trained on the residual function $r(x) = y(x) - F_k(x)$, and the resulting boosted classifier becomes $F_{k+1}(x) = f_1(x) + f_2(x) + \\dots + f_k(x) + f_{k+1}(x)$.\n",
    "\n",
    "* **Implement the methods `fit` and `predict` of the simple boosted regression tree below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBoostedTreeRegressor(sklearn.base.RegressorMixin):\n",
    "    \n",
    "    def __init__(self,max_depth=None,nb_trees=10):\n",
    "        self.trees = [sklearn.tree.DecisionTreeRegressor(max_depth=max_depth)\n",
    "                      for _ in range(nb_trees)]\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    def predict(self,X):\n",
    "        \n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-7289fe85d556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Add values to the Evaluation DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mEvaluation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mEvaluation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'evaluation'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvaluation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEvaluation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mEvaluation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'misclassified'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvaluation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predictions'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvaluation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'target'"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "Evaluation = {}\n",
    "\n",
    "boston   = sklearn.datasets.load_boston()\n",
    "diabetes = sklearn.datasets.load_diabetes()\n",
    "\n",
    "X = boston.data\n",
    "T = boston.target\n",
    "(Xtrain,Ttrain),(Xtest,Ttest) = utils.split(X,T)\n",
    "Evaluation['weights'] = 1/len(Xtrain)\n",
    "\n",
    "\n",
    "Tree_model = sklearn.tree.DecisionTreeRegressor(max_depth=1)\n",
    "model = Tree_model.fit(Xtrain,Ttrain) \n",
    "\n",
    "models.append(model)\n",
    "predictions = model.predict(Xtest)\n",
    "score = model.score(Xtest,Ttest)\n",
    "\n",
    "# Add values to the Evaluation DataFrame\n",
    "Evaluation['predictions'] = predictions\n",
    "Evaluation['evaluation'] = np.where(Evaluation['predictions'] == Evaluation['target'],1,0)\n",
    "Evaluation['misclassified'] = np.where(Evaluation['predictions'] != Evaluation['target'],1,0)\n",
    "\n",
    "# Calculate the misclassification rate and accuracy\n",
    "accuracy = sum(Evaluation['evaluation'])/len(Evaluation['evaluation'])\n",
    "misclassification = sum(Evaluation['misclassified'])/len(Evaluation['misclassified'])\n",
    "\n",
    "\n",
    "# Caclulate the error\n",
    "err = np.sum(Evaluation['weights']*Evaluation['misclassified'])/np.sum(Evaluation['weights'])\n",
    "\n",
    "\n",
    "# Calculate the alpha values\n",
    "alpha = np.log((1-err)/err)\n",
    "alphas.append(alpha)\n",
    "\n",
    "\n",
    "# Update the weights wi --> These updated weights are used in the sample_weight parameter\n",
    "# for the training of the next decision stump. \n",
    "Evaluation['weights'] *= np.exp(alpha*Evaluation['misclassified'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below compares the boosted tree regressor to the simple decision tree on the diabetes dataset. Here, we use for the decision tree a depth 2, that yields maximum accuracy on this dataset. As boosting allows to grows complex decisions from weak regressors, we set maximum tree depth to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree (optimal depth): | train: 0.462 | test: 0.334\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-75e3223c4426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnb_trees\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mregressor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleBoostedTreeRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb_trees\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mstrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregressor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiabetes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     print(\"boosting with %2d trees(s):     | train: %.3f | test: %.3f\"%\n\u001b[1;32m     12\u001b[0m           (nb_trees,strain,stest))\n",
      "\u001b[0;32m/Volumes/Study/TU-Berlin/ML1/09 - Decision Trees and Random Forests/Exercise sheet 8-9 (programming)-20210113/sheet08/utils.py\u001b[0m in \u001b[0;36mbenchmark\u001b[0;34m(predictor, dataset)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0macctr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTtrain\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnbtrials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0macctt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnbtrials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mr2_score\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;34m-\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \"\"\"\n\u001b[0;32m--> 588\u001b[0;31m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[1;32m    589\u001b[0m         y_true, y_pred, multioutput)\n\u001b[1;32m    590\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     95\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Benchmark for baseline decision tree model\n",
    "regressor = sklearn.tree.DecisionTreeRegressor(max_depth=2)\n",
    "strain,stest = utils.benchmark(regressor,diabetes)\n",
    "print(\"decision tree (optimal depth): | train: %.3f | test: %.3f\"%\n",
    "      (strain,stest))\n",
    "\n",
    "# Benchmark for the boosted tree regressor model with a growing number of trees\n",
    "for nb_trees in [1,2,4,8,16,32,64]:\n",
    "    regressor = SimpleBoostedTreeRegressor(max_depth=1,nb_trees=nb_trees)\n",
    "    strain,stest = utils.benchmark(regressor,diabetes)\n",
    "    print(\"boosting with %2d trees(s):     | train: %.3f | test: %.3f\"%\n",
    "          (nb_trees,strain,stest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like for the random forests, the boosted tree regressor also brings an improvement compared to the simple decision tree. Note that adding too many trees may still cause overfitting (here, a good number of trees is 16). If we would like to include more trees, an even weaker base model should be used if available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency of regression performance on model complexity\n",
    "\n",
    "Finally, we can study how the performance of each model depends on the tree depth. In this last experiment, the number of trees in the random forest and boosted model are kept fixed, and the tree depth is varied. Experiments are performed for all datasets and algorithms and results are shown as plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-e7240731a116>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0malgorithm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         acc = [utils.benchmark(algorithm(max_depth=i),dataset)[1]\n\u001b[0m\u001b[1;32m     17\u001b[0m                for i in depths]\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-116-e7240731a116>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0malgorithm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         acc = [utils.benchmark(algorithm(max_depth=i),dataset)[1]\n\u001b[0m\u001b[1;32m     17\u001b[0m                for i in depths]\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/Study/TU-Berlin/ML1/09 - Decision Trees and Random Forests/Exercise sheet 8-9 (programming)-20210113/sheet08/utils.py\u001b[0m in \u001b[0;36mbenchmark\u001b[0;34m(predictor, dataset)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0macctr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTtrain\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnbtrials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0macctt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnbtrials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mr2_score\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0;34m-\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \"\"\"\n\u001b[0;32m--> 588\u001b[0;31m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[1;32m    589\u001b[0m         y_true, y_pred, multioutput)\n\u001b[1;32m    590\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     95\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "depths     = [1,2,3,4,5,6,7,8]\n",
    "datasets   = [boston,diabetes]\n",
    "names      = ['boston','diabetes']\n",
    "algorithms = [sklearn.tree.DecisionTreeRegressor,\n",
    "              RandomForestRegressor,\n",
    "              SimpleBoostedTreeRegressor]\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for dataset,name in zip(datasets,names):\n",
    "    plt.figure()\n",
    "    plt.title(name)\n",
    "    \n",
    "    for algorithm in algorithms:\n",
    "        \n",
    "        acc = [utils.benchmark(algorithm(max_depth=i),dataset)[1]\n",
    "               for i in depths]\n",
    "        \n",
    "        plt.plot(depths,acc,'o-',label=algorithm.__name__)\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('tree depth')\n",
    "    plt.ylabel('coefficient of determination')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that the random forest method tends to prefer deep trees. Indeed, the variance increase caused by deeper trees is countered by the averaging mechanism. Conversely, the boosting algorithm prefers small trees as it is able to build complex models even from simple weak regressors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
